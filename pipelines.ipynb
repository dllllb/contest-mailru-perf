{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "- http://mlbootcamp.ru/championship/7/\n",
    "\n",
    "# Discussions:\n",
    "- [Скоро открытие ML Boot Camp III, блог mail.ru](https://habrahabr.ru/company/mailru/blog/321016/)\n",
    "  - predict time/(m*n*k) instead of time\n",
    "    - according to complimentary article\n",
    "  - https://github.com/KarachunMikhail/mlbootcamp_matrix/blob/master/mlbootcamp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition.truncated_svd import TruncatedSVD\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble.bagging import BaggingRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection.univariate_selection import SelectKBest, f_regression\n",
    "from sklearn.gaussian_process import GaussianProcess\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.mixture.gmm import GMM\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing.data import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ds_tools/dstools/ml/ensemble.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitri/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%run ds_tools/dstools/ml/xgboost_tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.average(np.abs((y_pred - y_true) / y_true), axis=0)\n",
    "\n",
    "\n",
    "def mape_evalerror(preds, dtrain):\n",
    "    return 'mape', mape(dtrain.get_label(), preds)\n",
    "\n",
    "\n",
    "def mape_obj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    grad = (preds - labels) / labels\n",
    "    hess = np.full(len(preds), 1.)\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "def ybin(y):\n",
    "    return np.digitize(np.log2(y), bins=np.arange(0, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataset(path):\n",
    "    x = pd.read_csv(path)\n",
    "    x['memFreq'] = x.memFreq.replace('None', np.nan).astype(np.float64)\n",
    "    x['memtRFC'] = x.memtRFC.replace('None', np.nan).astype(np.float64)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_test(est):\n",
    "    x = dataset('x_train.csv.gz')\n",
    "\n",
    "    y = pd.read_csv('y_train.csv', squeeze=True)\n",
    "\n",
    "    cv = StratifiedKFold(ybin(y), 5, shuffle=True)\n",
    "\n",
    "    scores = cross_val_score(est, x, y, scoring=make_scorer(mape), cv=cv)\n",
    "    print('mean: {mean}, std: {std}'.format(mean=scores.mean(), std=scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submission(est, name='results'):\n",
    "    x_tr = dataset('x_train.csv.gz')\n",
    "    y_tr = pd.read_csv('y_train.csv', squeeze=True)\n",
    "\n",
    "    m = est.fit(x_tr, y_tr)\n",
    "\n",
    "    x_test = dataset('x_test.csv.gz')\n",
    "\n",
    "    y_pred = m.predict(x_test)\n",
    "\n",
    "    res = pd.Series(y_pred, index=x_test.index, name='time')\n",
    "    res.to_csv(name + '.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_vs_true(est, path):\n",
    "    x_tr = dataset('x_train.csv.gz')\n",
    "    y_tr = pd.read_csv('y_train.csv', squeeze=True)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_tr, y_tr, train_size=0.9)\n",
    "    y_pred = est.fit(x_train, y_train).predict(x_test)\n",
    "\n",
    "    pd.DataFrame({'pred': y_pred, 'true': y_test}).to_csv(path, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_transform(x):\n",
    "    return x.drop(['memType', 'os', 'cpuFull', 'cpuArch'], axis=1)\n",
    "\n",
    "drop_transformer = FunctionTransformer(drop_transform, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params_base = {\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"eta\": 0.1,\n",
    "    \"min_child_weight\": 6,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.5,\n",
    "    \"silent\": 1,\n",
    "    \"max_depth\": 4,\n",
    "    \"num_rounds\": 10000,\n",
    "    \"num_es_rounds\": 120,\n",
    "    \"es_share\": .2,\n",
    "    'eval_func': mape_evalerror,\n",
    "    'ybin_func': ybin,\n",
    "}\n",
    "\n",
    "# mean: 0.18989341816, std: 0.0160804510843\n",
    "# cv execution time: 53.5373871326 sec\n",
    "est1 = make_pipeline(\n",
    "    drop_transformer,\n",
    "    XGBoostRegressor(**xgb_params_base),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params2_3 = {\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"eta\": 0.01,\n",
    "    \"min_child_weight\": 6,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.5,\n",
    "    \"silent\": 1,\n",
    "    \"max_depth\": 10,\n",
    "    \"num_rounds\": 10000,\n",
    "    'eval_func': mape_evalerror,\n",
    "    'ybin_func': ybin,\n",
    "    'objective_func': mape_obj,\n",
    "    'num_parallel_tree': 2,\n",
    "}\n",
    "\n",
    "# mean: 0.100802273555, std: 0.00297206137388\n",
    "# cv execution time: 1551.09467602 sec\n",
    "est2_3 = make_pipeline(\n",
    "    drop_transformer,\n",
    "    XGBoostRegressor(**xgb_params2_3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params2_4q = {\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"eta\": 0.05,\n",
    "    \"min_child_weight\": 6,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.5,\n",
    "    \"silent\": 1,\n",
    "    \"max_depth\": 10,\n",
    "    \"num_rounds\": 1000,\n",
    "    'eval_func': mape_evalerror,\n",
    "    'ybin_func': ybin,\n",
    "    'objective_func': mape_obj,\n",
    "    'num_parallel_tree': 2,\n",
    "    'es_share': 0.,\n",
    "}\n",
    "\n",
    "# mean: 0.115525732228, std: 0.00485697975408\n",
    "# cv execution time: 73.8630280495 sec\n",
    "est2_4q = make_pipeline(\n",
    "    drop_transformer,\n",
    "    XGBoostRegressor(**xgb_params2_4q),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params4_8 = {\n",
    "    \"objective\": \"count:poisson\",\n",
    "    \"eta\": 0.01,\n",
    "    \"min_child_weight\": 6,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.3,\n",
    "    \"silent\": 1,\n",
    "    \"max_depth\": 10,\n",
    "    \"num_rounds\": 5000,\n",
    "    'eval_func': mape_evalerror,\n",
    "    'ybin_func': ybin,\n",
    "    'num_parallel_tree': 2,\n",
    "    'es_share': 0.,\n",
    "}\n",
    "\n",
    "# mean: 0.0815279171801, std: 0.00207426442531\n",
    "# cv execution time: 467.35233593 sec\n",
    "est4_8 = make_pipeline(\n",
    "    drop_transformer,\n",
    "    XGBoostRegressor(**xgb_params4_8),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params4_8q = {\n",
    "    \"objective\": \"count:poisson\",\n",
    "    \"eta\": 0.05,\n",
    "    \"min_child_weight\": 6,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.3,\n",
    "    \"silent\": 1,\n",
    "    \"max_depth\": 10,\n",
    "    \"num_rounds\": 1000,\n",
    "    'eval_func': mape_evalerror,\n",
    "    'ybin_func': ybin,\n",
    "    'num_parallel_tree': 2,\n",
    "    'es_share': 0.\n",
    "}\n",
    "\n",
    "# mean: 0.0895119550018, std: 0.00514490683152\n",
    "# cv execution time: 82.7434458733 sec\n",
    "est4_8q = make_pipeline(\n",
    "    drop_transformer,\n",
    "    XGBoostRegressor(**xgb_params4_8q),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean: 0.188509803951, std: 0.0900312025872\n",
    "# cv execution time: 101.356594801 sec\n",
    "est7 = make_pipeline(\n",
    "    drop_transformer,\n",
    "    Imputer(),\n",
    "    StandardScaler(),\n",
    "    PCA(n_components=100),\n",
    "    XGBoostRegressor(**xgb_params4_8q),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean: 0.113271580876, std: 0.00501539399312\n",
    "# cv execution time: 974.13361311 sec\n",
    "est8 = make_pipeline(\n",
    "    drop_transformer,\n",
    "    Imputer(),\n",
    "    ExtraTreesRegressor(n_estimators=10000, n_jobs=-1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitri/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:52: DeprecationWarning: Class GaussianProcess is deprecated; GaussianProcess was deprecated in version 0.18 and will be removed in 0.20. Use the GaussianProcessRegressor instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# mean: 0.40358272167, std: 0.0333605756569\n",
    "# cv execution time: 28.1571791172 sec\n",
    "est11 = make_pipeline(\n",
    "    drop_transformer,\n",
    "    Imputer(),\n",
    "    StandardScaler(),\n",
    "    PCA(n_components=30),\n",
    "    GaussianProcess(theta0=2.),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca2c_transformer = make_pipeline(\n",
    "    drop_transformer,\n",
    "    Imputer(),\n",
    "    StandardScaler(),\n",
    "    PCA(n_components=2),\n",
    ")\n",
    "\n",
    "os_transformer = make_pipeline(\n",
    "    FunctionTransformer(lambda x: x.os, validate=False),\n",
    "    CountVectorizer(),\n",
    "    TruncatedSVD(n_components=10),\n",
    ")\n",
    "\n",
    "arch_transformer = FunctionTransformer(lambda x: pd.get_dummies(x.cpuArch), validate=False)\n",
    "\n",
    "gmm_transformer = make_pipeline(\n",
    "    drop_transformer,\n",
    "    Imputer(),\n",
    "    StandardScaler(),\n",
    "    PCA(n_components=2),\n",
    "    FunctionTransformer(lambda x: GMM(n_components=3).fit_predict(x)[np.newaxis].T)\n",
    ")\n",
    "\n",
    "# mean: 0.0841074580969, std: 0.00253239384855\n",
    "# cv execution time: 693.359354973 sec\n",
    "est13 = make_pipeline(\n",
    "    make_union(\n",
    "        drop_transformer,\n",
    "        gmm_transformer,\n",
    "        os_transformer,\n",
    "        arch_transformer,\n",
    "        pca2c_transformer,\n",
    "    ),\n",
    "    XGBoostRegressor(**xgb_params4_8),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean: 0.0951764830567, std: 0.00784125475434\n",
    "# cv execution time: 876.678437948 sec\n",
    "est14 = make_pipeline(\n",
    "    drop_transformer,\n",
    "    Imputer(),\n",
    "    BaggingRegressor(\n",
    "        base_estimator=XGBoostRegressor(**xgb_params4_8q),\n",
    "        n_estimators=10,\n",
    "        max_features=1.,\n",
    "        max_samples=1.,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params15 = {\n",
    "    \"objective\": \"count:poisson\",\n",
    "    \"eta\": 0.05,\n",
    "    \"min_child_weight\": 6,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.3,\n",
    "    \"silent\": 1,\n",
    "    \"max_depth\": 10,\n",
    "    \"num_rounds\": 5000,\n",
    "    'eval_func': mape_evalerror,\n",
    "    'ybin_func': ybin,\n",
    "    'num_parallel_tree': 2,\n",
    "}\n",
    "\n",
    "# mean: 0.126245924707, std: 0.00954889171685\n",
    "# cv execution time: 158.827933073 sec\n",
    "est15 = make_pipeline(\n",
    "    drop_transformer,\n",
    "    Imputer(),\n",
    "    StandardScaler(),\n",
    "    PolynomialFeatures(degree=2, interaction_only=True),\n",
    "    SelectKBest(f_regression, 200),\n",
    "    XGBoostRegressor(**xgb_params15),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean: 0.287046299445, std: 0.0499242435477\n",
    "# cv execution time: 6.1778948307 sec\n",
    "est16 = PerGroupRegressor(\n",
    "    estimator=make_pipeline(\n",
    "        drop_transformer,\n",
    "        Imputer(),\n",
    "        StandardScaler(),\n",
    "        Ridge(alpha=10)\n",
    "    ),\n",
    "    split_condition=['os', 'cpuFreq', 'memSize_MB'],\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params17 = {\n",
    "    \"booster\": 'gblinear',\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"eta\": 0.01,\n",
    "    \"num_rounds\": 100,\n",
    "    \"es_share\": .0,\n",
    "    'lambda': .5,\n",
    "    'alpha': .5,\n",
    "}\n",
    "\n",
    "# mean: 0.296550976215, std: 0.0348970237629\n",
    "# cv execution time: 26.448786974 sec\n",
    "est17 = PerGroupRegressor(\n",
    "    estimator=make_pipeline(\n",
    "        drop_transformer,\n",
    "        Imputer(),\n",
    "        StandardScaler(),\n",
    "        XGBoostRegressor(**xgb_params17)\n",
    "    ),\n",
    "    split_condition=['os', 'cpuFreq', 'memSize_MB'],\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean: 0.120320752517, std: 0.00786868554231\n",
    "# cv execution time: 866.464553833 sec\n",
    "est18 = PerGroupRegressor(\n",
    "    estimator=make_pipeline(\n",
    "        drop_transformer,\n",
    "        Imputer(),\n",
    "        StandardScaler(),\n",
    "        XGBoostRegressor(**xgb_params4_8q)\n",
    "    ),\n",
    "    split_condition=['os', 'cpuFreq', 'memSize_MB'],\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
